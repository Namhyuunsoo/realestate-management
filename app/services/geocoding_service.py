# app/services/geocoding_service.py

import os
import time
import logging
import pandas as pd
import requests
from typing import Dict, List, Tuple, Optional
from flask import current_app
from .sheet_fetcher import read_local_listing_sheet
from .geocode_cache import load_geocode_cache, save_geocode_cache

class GeocodingService:
    """ì§€ì˜¤ì½”ë”© ìë™í™” ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        # Flask ì»¨í…ìŠ¤íŠ¸ê°€ ìˆì„ ë•Œë§Œ ì„¤ì • ë¡œë“œ
        try:
            self.naver_client_id = current_app.config.get("NAVER_MAPS_NCP_CLIENT_ID", "")
            self.naver_client_secret = current_app.config.get("NAVER_MAPS_NCP_CLIENT_SECRET", "")
            self.geocode_cache_file = current_app.config["GEOCODE_CACHE_FILE"]
            self.map_cache_file = current_app.config["MAP_CACHE_FILENAME"]
            self.data_dir = current_app.config["DATA_DIR"]
        except RuntimeError:
            # Flask ì»¨í…ìŠ¤íŠ¸ê°€ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ê°’ ì‚¬ìš©
            self.naver_client_id = ""
            self.naver_client_secret = ""
            self.geocode_cache_file = "geocode_cache.json"
            self.map_cache_file = "ì§€ë„ìºì‹œ.xlsx"
            self.data_dir = "./data"
        
        # ë¡œê¹… ì„¤ì •
        logging.basicConfig(level=logging.INFO)
        self.logger = logging.getLogger(__name__)
        
        # API í‚¤ í™•ì¸
        if not self.naver_client_id or not self.naver_client_secret:
            self.logger.warning("âš ï¸ ë„¤ì´ë²„ ì§€ì˜¤ì½”ë”© API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            self.logger.warning("   NAVER_MAPS_NCP_CLIENT_IDì™€ NAVER_MAPS_NCP_CLIENT_SECRET í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
    
    def update_config(self):
        """Flask ì»¨í…ìŠ¤íŠ¸ì—ì„œ ì„¤ì • ì—…ë°ì´íŠ¸"""
        try:
            self.naver_client_id = current_app.config.get("NAVER_MAPS_NCP_CLIENT_ID", "")
            self.naver_client_secret = current_app.config.get("NAVER_MAPS_NCP_CLIENT_SECRET", "")
            self.geocode_cache_file = current_app.config["GEOCODE_CACHE_FILE"]
            self.map_cache_file = current_app.config["MAP_CACHE_FILENAME"]
            self.data_dir = current_app.config["DATA_DIR"]
            self.logger.info("âœ… ì„¤ì •ì´ Flask ì»¨í…ìŠ¤íŠ¸ì—ì„œ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤.")
        except RuntimeError as e:
            self.logger.error(f"ì„¤ì • ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
    
    def extract_addresses_from_listings(self) -> List[str]:
        """ìƒê°€ì„ëŒ€ì°¨.xlsxì—ì„œ ëª¨ë“  ì£¼ì†Œ ì¶”ì¶œ"""
        try:
            rows = read_local_listing_sheet()
            if not rows or len(rows) < 2:
                self.logger.warning("ìƒê°€ì„ëŒ€ì°¨ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return []
            
            header = rows[0]
            hdr_map = self._normalize_headers(header)
            
            addresses = []
            for i, row in enumerate(rows[1:], start=1):
                try:
                    # ì£¼ì†Œ êµ¬ì„±: ì§€ì—­2 + ì§€ì—­ + ì§€ë²ˆ
                    region2 = row[hdr_map.get("ì§€ì—­2", -1)] if "ì§€ì—­2" in hdr_map else ""
                    region = row[hdr_map.get("ì§€ì—­", -1)] if "ì§€ì—­" in hdr_map else ""
                    lot = row[hdr_map.get("ì§€ë²ˆ", -1)] if "ì§€ë²ˆ" in hdr_map else ""
                    
                    # ì£¼ì†Œê°€ ì™„ì„±ëœ ê²½ìš°ë§Œ ì¶”ê°€
                    if region2 and region and lot:
                        address = f"{region2} {region} {lot}".strip()
                        if address not in addresses:
                            addresses.append(address)
                            
                except Exception as e:
                    self.logger.warning(f"Row {i} ì£¼ì†Œ íŒŒì‹± ì‹¤íŒ¨: {e}")
                    continue
            
            self.logger.info(f"ìƒê°€ì„ëŒ€ì°¨ì—ì„œ {len(addresses)}ê°œ ì£¼ì†Œ ì¶”ì¶œ ì™„ë£Œ")
            return addresses
            
        except Exception as e:
            self.logger.error(f"ì£¼ì†Œ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return []
    
    def _normalize_headers(self, header_row: List[str]) -> Dict[str, int]:
        """í—¤ë” ì •ê·œí™”"""
        mapping = {}
        for i, col in enumerate(header_row):
            mapping[col] = i
        return mapping
    
    def get_existing_coordinates(self) -> Dict[str, Tuple[float, float]]:
        """ì§€ë„ìºì‹œì—ì„œ ê¸°ì¡´ ì¢Œí‘œ ê°€ì ¸ì˜¤ê¸°"""
        try:
            map_cache_path = os.path.join(self.data_dir, "raw", self.map_cache_file)
            if not os.path.exists(map_cache_path):
                self.logger.warning(f"ì§€ë„ìºì‹œ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {map_cache_path}")
                return {}
            
            # Excel íŒŒì¼ ì½ê¸°
            xls = pd.ExcelFile(map_cache_path)
            sheet = "ì§€ë„ìºì‹œ" if "ì§€ë„ìºì‹œ" in xls.sheet_names else xls.sheet_names[0]
            
            df = pd.read_excel(map_cache_path, sheet_name=sheet, dtype=str).fillna("")
            
            coordinates = {}
            for _, row in df.iterrows():
                addr = row.get("ì£¼ì†Œ", "").strip()
                lat = row.get("ìœ„ë„", "").strip()
                lng = row.get("ê²½ë„", "").strip()
                
                if addr and lat and lng:
                    try:
                        lat_val = float(lat)
                        lng_val = float(lng)
                        if -90 <= lat_val <= 90 and -180 <= lng_val <= 180:
                            coordinates[addr] = (lat_val, lng_val)
                    except ValueError:
                        continue
            
            self.logger.info(f"ì§€ë„ìºì‹œì—ì„œ {len(coordinates)}ê°œ ì¢Œí‘œ ë¡œë“œ ì™„ë£Œ")
            return coordinates
            
        except Exception as e:
            self.logger.error(f"ì§€ë„ìºì‹œ ì½ê¸° ì‹¤íŒ¨: {e}")
            return {}
    
    def geocode_address(self, address: str) -> Optional[Tuple[float, float]]:
        """ë„¤ì´ë²„ ì§€ì˜¤ì½”ë”© APIë¡œ ì£¼ì†Œë¥¼ ì¢Œí‘œë¡œ ë³€í™˜"""
        if not self.naver_client_id or not self.naver_client_secret:
            self.logger.warning("ë„¤ì´ë²„ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return None
        
        try:
            url = "https://naveropenapi.apigw.ntruss.com/map-geocode/v2/geocode"
            headers = {
                "X-NCP-APIGW-API-KEY-ID": self.naver_client_id,
                "X-NCP-APIGW-API-KEY": self.naver_client_secret
            }
            params = {
                "query": address,
                "coordinate": "latlng"
            }
            
            response = requests.get(url, headers=headers, params=params, timeout=10)
            response.raise_for_status()
            
            data = response.json()
            
            if data.get("status") == "OK" and data.get("addresses"):
                address_info = data["addresses"][0]
                lat = float(address_info["y"])
                lng = float(address_info["x"])
                
                # í•œêµ­ ì§€ì—­ ë²”ìœ„ í™•ì¸
                if 33 <= lat <= 39 and 124 <= lng <= 132:
                    self.logger.info(f"ì§€ì˜¤ì½”ë”© ì„±ê³µ: {address} â†’ ({lat}, {lng})")
                    return (lat, lng)
                else:
                    self.logger.warning(f"í•œêµ­ ì§€ì—­ ë²”ìœ„ë¥¼ ë²—ì–´ë‚œ ì¢Œí‘œ: {address} â†’ ({lat}, {lng})")
                    return None
            else:
                self.logger.warning(f"ì§€ì˜¤ì½”ë”© ì‹¤íŒ¨: {address} - {data.get('errorMessage', 'Unknown error')}")
                return None
                
        except Exception as e:
            self.logger.error(f"ì§€ì˜¤ì½”ë”© API í˜¸ì¶œ ì‹¤íŒ¨ ({address}): {e}")
            return None
    
    def update_map_cache(self, new_coordinates: Dict[str, Tuple[float, float]]):
        """ì§€ë„ìºì‹œ Excel íŒŒì¼ ì—…ë°ì´íŠ¸"""
        try:
            map_cache_path = os.path.join(self.data_dir, "raw", self.map_cache_file)
            
            # ê¸°ì¡´ ë°ì´í„° ì½ê¸°
            existing_data = []
            if os.path.exists(map_cache_path):
                try:
                    xls = pd.ExcelFile(map_cache_path)
                    sheet = "ì§€ë„ìºì‹œ" if "ì§€ë„ìºì‹œ" in xls.sheet_names else xls.sheet_names[0]
                    df = pd.read_excel(map_cache_path, sheet_name=sheet, dtype=str).fillna("")
                    
                    for _, row in df.iterrows():
                        existing_data.append({
                            "ì£¼ì†Œ": row.get("ì£¼ì†Œ", ""),
                            "ìœ„ë„": row.get("ìœ„ë„", ""),
                            "ê²½ë„": row.get("ê²½ë„", ""),
                            "ì—…ë°ì´íŠ¸ì¼": row.get("ì—…ë°ì´íŠ¸ì¼", "")
                        })
                except Exception as e:
                    self.logger.warning(f"ê¸°ì¡´ ì§€ë„ìºì‹œ ì½ê¸° ì‹¤íŒ¨: {e}")
            
            # ìƒˆ ì¢Œí‘œ ì¶”ê°€/ì—…ë°ì´íŠ¸
            current_time = pd.Timestamp.now().strftime("%Y-%m-%d %H:%M:%S")
            
            for addr, (lat, lng) in new_coordinates.items():
                # ê¸°ì¡´ì— ìˆëŠ” ì£¼ì†Œì¸ì§€ í™•ì¸
                existing = next((item for item in existing_data if item["ì£¼ì†Œ"] == addr), None)
                
                if existing:
                    # ê¸°ì¡´ ì£¼ì†Œ ì—…ë°ì´íŠ¸
                    existing["ìœ„ë„"] = str(lat)
                    existing["ê²½ë„"] = str(lng)
                    existing["ì—…ë°ì´íŠ¸ì¼"] = current_time
                else:
                    # ìƒˆ ì£¼ì†Œ ì¶”ê°€
                    existing_data.append({
                        "ì£¼ì†Œ": addr,
                        "ìœ„ë„": str(lat),
                        "ê²½ë„": str(lng),
                        "ì—…ë°ì´íŠ¸ì¼": current_time
                    })
            
            # Excel íŒŒì¼ë¡œ ì €ì¥
            df = pd.DataFrame(existing_data)
            
            # ë°±ì—… íŒŒì¼ ìƒì„±
            if os.path.exists(map_cache_path):
                backup_path = map_cache_path.replace(".xlsx", f"_backup_{int(time.time())}.xlsx")
                os.rename(map_cache_path, backup_path)
                self.logger.info(f"ê¸°ì¡´ ì§€ë„ìºì‹œ ë°±ì—…: {backup_path}")
            
            # ìƒˆ íŒŒì¼ ì €ì¥
            with pd.ExcelWriter(map_cache_path, engine='openpyxl') as writer:
                df.to_excel(writer, sheet_name="ì§€ë„ìºì‹œ", index=False)
            
            self.logger.info(f"ì§€ë„ìºì‹œ ì—…ë°ì´íŠ¸ ì™„ë£Œ: {len(existing_data)}ê°œ ì£¼ì†Œ")
            
        except Exception as e:
            self.logger.error(f"ì§€ë„ìºì‹œ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
    
    def run_geocoding_update(self) -> Dict[str, int]:
        """ì§€ì˜¤ì½”ë”© ì—…ë°ì´íŠ¸ ì‹¤í–‰"""
        try:
            self.logger.info("ğŸš€ ì§€ì˜¤ì½”ë”© ì—…ë°ì´íŠ¸ ì‹œì‘...")
            
            # 1. ìƒê°€ì„ëŒ€ì°¨ì—ì„œ ëª¨ë“  ì£¼ì†Œ ì¶”ì¶œ
            all_addresses = self.extract_addresses_from_listings()
            if not all_addresses:
                return {"total": 0, "new": 0, "updated": 0, "failed": 0}
            
            # 2. ê¸°ì¡´ ì¢Œí‘œ ê°€ì ¸ì˜¤ê¸°
            existing_coordinates = self.get_existing_coordinates()
            
            # 3. ìƒˆë¡œ ì§€ì˜¤ì½”ë”©ì´ í•„ìš”í•œ ì£¼ì†Œ ì°¾ê¸°
            new_addresses = [addr for addr in all_addresses if addr not in existing_coordinates]
            
            self.logger.info(f"ì´ ì£¼ì†Œ: {len(all_addresses)}, ê¸°ì¡´ ì¢Œí‘œ: {len(existing_coordinates)}, ìƒˆ ì£¼ì†Œ: {len(new_addresses)}")
            
            if not new_addresses:
                self.logger.info("ìƒˆë¡œ ì§€ì˜¤ì½”ë”©ì´ í•„ìš”í•œ ì£¼ì†Œê°€ ì—†ìŠµë‹ˆë‹¤.")
                return {"total": len(all_addresses), "new": 0, "updated": 0, "failed": 0}
            
            # 4. ìƒˆ ì£¼ì†Œë“¤ ì§€ì˜¤ì½”ë”©
            new_coordinates = {}
            failed_addresses = []
            
            for i, address in enumerate(new_addresses, 1):
                self.logger.info(f"ì§€ì˜¤ì½”ë”© ì§„í–‰ ì¤‘: {i}/{len(new_addresses)} - {address}")
                
                coordinates = self.geocode_address(address)
                if coordinates:
                    new_coordinates[address] = coordinates
                else:
                    failed_addresses.append(address)
                
                # API í˜¸ì¶œ ì œí•œ ë°©ì§€ (ì´ˆë‹¹ 1íšŒ)
                if i < len(new_addresses):
                    time.sleep(1)
            
            # 5. ì§€ë„ìºì‹œ ì—…ë°ì´íŠ¸
            if new_coordinates:
                self.update_map_cache(new_coordinates)
            
            # 6. ê²°ê³¼ ìš”ì•½
            result = {
                "total": len(all_addresses),
                "new": len(new_coordinates),
                "updated": 0,  # í˜„ì¬ëŠ” ìƒˆ ì£¼ì†Œë§Œ ì¶”ê°€
                "failed": len(failed_addresses)
            }
            
            self.logger.info(f"âœ… ì§€ì˜¤ì½”ë”© ì—…ë°ì´íŠ¸ ì™„ë£Œ: {result}")
            
            if failed_addresses:
                self.logger.warning(f"ì‹¤íŒ¨í•œ ì£¼ì†Œë“¤: {failed_addresses}")
            
            return result
            
        except Exception as e:
            self.logger.error(f"ì§€ì˜¤ì½”ë”© ì—…ë°ì´íŠ¸ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            return {"total": 0, "new": 0, "updated": 0, "failed": 0}
